{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune T5 Paraphrase model to generate better Jeopardy question prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import hashlib\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "from trl.t5 import T5HeadWithValueModel, respond_to_batch\n",
    "from trl.ppo import PPOTrainer\n",
    "from trl.core import pad_to_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lm_name\": \"Vamsi/T5_Paraphrase_Paws\",\n",
    "    \"ref_lm_name\": \"Vamsi/T5_Paraphrase_Paws\",\n",
    "    \"cls_model_name\": \"vblagoje/bert-base-searchqa\",\n",
    "    \"tk_name\": \"t5-base\",\n",
    "    \"steps\": 25600,\n",
    "    \"batch_size\": 4,\n",
    "    \"forward_batch_size\": 4,\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_len\": 5,\n",
    "    \"txt_out_len\": 128,\n",
    "    \"lr\": 1.41e-5,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we load a GPT2 model called `gpt2_imdb`. This model was additionally fine-tuned on the IMDB dataset for 1 epoch with the huggingface [script](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py) (no special settings). The other parameters are mostly taken from the original paper [\"Fine-Tuning Language Models from Human Preferences\"](\n",
    "https://arxiv.org/pdf/1909.08593.pdf). This model as well as the BERT model is available in the Huggingface model zoo [here](https://huggingface.co/models). The following code should automatically download the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize W&B logger\n",
    "We use `wandb`to log all the metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Offline run mode, not syncing to the cloud.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` to enable cloud syncing.\n"
     ]
    },
    {
     "data": {
      "text/html": "<h1>Run(2cavrqhq)</h1><iframe src=\"\" style=\"border:none;width:100%;height:400px\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fe8c22c0760>"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name='run-42', project='t5-aqa', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SearchQA and convert it to SQuAD format\n",
    "Description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(txt):\n",
    "  cleanr = re.compile(\"<.*?>\")\n",
    "  cleantext = re.sub(cleanr, \" \", txt)\n",
    "  return cleantext\n",
    "\n",
    "def remove_special_chars(txt):\n",
    "  pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
    "  result = re.sub(pat, \"\", txt)\n",
    "  return re.sub(\"\\n\", \"\", result)\n",
    "\n",
    "\n",
    "def clean(txt):\n",
    "  return strip_html(remove_special_chars(txt))\n",
    "\n",
    "def convertSearchQAExampleToSquadExample(example):\n",
    "  snippets = example[\"search_results\"][\"snippets\"][:10]\n",
    "  snippets = [x for x in snippets if x != None]\n",
    "  context = \"\".join(snippets)\n",
    "  answers = {}\n",
    "  answer_for_match = ' ' + re.escape(example[\"answer\"]) + ' '\n",
    "  id = hashlib.new(\"sha1\", example[\"question\"].encode())\n",
    "  if re.search(answer_for_match, context):\n",
    "    matches = re.finditer(answer_for_match, context)\n",
    "    answer_start = [pos.start() + 1 for pos in matches]\n",
    "    answers = {\n",
    "          'answer_start': answer_start,\n",
    "          'text': [example[\"answer\"]] * len(answer_start)\n",
    "      }\n",
    "\n",
    "  return {\"id\": id.hexdigest(),\n",
    "          \"title\": example[\"question\"],\n",
    "          \"question\": example[\"question\"],\n",
    "          \"answers\": answers,\n",
    "          \"context\": clean(context)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SearchQA and convert it to SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset search_qa (/Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63)\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-1324614813ad4b0d.arrow\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-73b41b39d9de9e01.arrow\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-bce669f6e324a00c.arrow\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-84d3f8dffcef1123.arrow\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-0a4ee215cacef44f.arrow\n",
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-7253ff21a2b2d7d8.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load SearchQA\n",
    "search_qa = load_dataset(\"search_qa\", \"train_test_val\")\n",
    "\n",
    "#clean up and convert to SQuAD format\n",
    "squad_qa = search_qa.map(convertSearchQAExampleToSquadExample, remove_columns=search_qa[\"train\"].column_names)\n",
    "\n",
    "#filter no answer questions\n",
    "squad_qa = squad_qa.filter(lambda example: example[\"answers\"][\"answer_start\"] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an example entry item in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'answers': {'answer_start': [18], 'text': ['Jesse James']},\n 'context': \"In the Wild West, Jesse James was legendary  a Robin Hoodlike figure who the public loved and lawmakers hated. The outlaw's notorious bank robbing spree...Jesse James, one of America's most notorious outlaws, is shot to death by Robert Ford, a member of his gang who hoped to collect the bounty on Jesse's head.\",\n 'id': 'b64e19f081a8b60c3a2b6742bd66a7275d46b5a3',\n 'question': 'Outlaw: \"Murdered by a traitor and a coward whose name is not worthy to appear here\"',\n 'title': 'Outlaw: \"Murdered by a traitor and a coward whose name is not worthy to appear here\"'}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_qa[\"train\"][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QA pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(config[\"cls_model_name\"])\n",
    "q_tokenizer = AutoTokenizer.from_pretrained(config[\"cls_model_name\"])\n",
    "#qa = pipeline(\"question-answering\", model=qa_model, tokenizer=q_tokenizer)\n",
    "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=q_tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs are the logits for the negative and positive class. We will use the logits for positive class as a reward signal for the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.8468492031097412, 'start': 18, 'end': 29, 'answer': 'Jesse James'}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_example_id = 6\n",
    "context = squad_qa[\"train\"][training_example_id][\"context\"]\n",
    "q = squad_qa[\"train\"][training_example_id][\"question\"]\n",
    "pipeline_answer = qa_pipeline(question=q, context=context)\n",
    "pipeline_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting reward signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_metric(\"squad\")\n",
    "\n",
    "def f1_score(prediction, reference):\n",
    "\n",
    "  predictions = [{'prediction_text': prediction, 'id': '1'}]\n",
    "  references = [{'answers':  reference, 'id': '1'}]\n",
    "  r = squad.compute(predictions=predictions, references=references)\n",
    "  return r.get(\"f1\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "100.0"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pipeline_answer[\"answer\"], squad_qa[\"train\"][training_example_id][\"answers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model with a value head and the tokenizer. We load the model twice; the first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This serves as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5HeadWithValueModel were not initialized from the model checkpoint at Vamsi/T5_Paraphrase_Paws and are newly initialized: ['v_head.state_representation.weight', 'v_head.state_representation.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of T5HeadWithValueModel were not initialized from the model checkpoint at Vamsi/T5_Paraphrase_Paws and are newly initialized: ['v_head.state_representation.weight', 'v_head.state_representation.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "paraphrase_model = T5HeadWithValueModel.from_pretrained(config['lm_name'])\n",
    "paraphrase_model_ref = T5HeadWithValueModel.from_pretrained(config['ref_lm_name'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['tk_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch model with wandb\n",
    "This wandb magic logs the gradients and weights of the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<wandb.wandb_torch.TorchGraph at 0x7fe7d4c4e4f0>]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(paraphrase_model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move models to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `cuda` is available move the computations to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = paraphrase_model.to(device)\n",
    "_ = paraphrase_model_ref.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize all IMDB in advance to avoid tokenizing twice. In the first step we encode the queries and slice the first `txt_in_len` tokens. In a second step we decode these tokens back to text for later display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/vblagoje/.cache/huggingface/datasets/search_qa/train_test_val/1.0.0/a2a9f2281af3826aaca532a2214573f11c1979499ac14b5639c7f02ac3ff0c63/cache-487c7b47ce1067e4.arrow\n"
     ]
    }
   ],
   "source": [
    "squad_qa_encoded = squad_qa[\"train\"].map(lambda x: tokenizer(\"paraphrase: \" + x['question'] + \" </s>\", padding=\"max_length\", truncation=True), batched=False)\n",
    "squad_qa_encoded.set_format(type='torch', columns=['input_ids', 'attention_mask'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "\n",
    "The training loop consists of the following steps:\n",
    "1. Get a batch of queries\n",
    "2. Get the query responses from the policy\n",
    "3. Join query and responses and tokenize for BERT analysis\n",
    "4. Get sentiments for query/responses from BERT\n",
    "5. Optimize policy with PPO using the (query, response, reward) triplet\n",
    "6. Log all the training statistics\n",
    "\n",
    "**Forward batching**\n",
    "\n",
    "Since the models can be fairly big and we want to rollout large PPO batches this can lead to out-of-memory errors when doing the forward passes for text generation and sentiment analysis. We introduce the parameter `forward_batch_size` to split the forward passes into smaller batches. Although this hurts performance a little this is neglectible compared to the computations of the backward passes when optimizing the model. The same parameter is used in the `PPOTrainer` when doing forward passes. The `batch_size` should multiple of `forward_batch_size`.\n",
    "\n",
    "**Training time**\n",
    "\n",
    "This step takes **~2h** on a P6000 GPU with the above specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs = config['forward_batch_size']\n",
    "train_ds = squad_qa_encoded\n",
    "pop_size = range(len(train_ds))\n",
    "\n",
    "#for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config['batch_size'])))):\n",
    "torch.cuda.empty_cache()\n",
    "logs = dict()\n",
    "game_data = dict()\n",
    "timing = dict()\n",
    "t0 = time.time()\n",
    "\n",
    "#### get a batch of questions from the dataset\n",
    "indices = np.random.choice(pop_size, size=config['batch_size'], replace=False)\n",
    "sample = train_ds.select(indices=indices)\n",
    "\n",
    "game_data['question'] = sample['question']\n",
    "question_tensors = sample['input_ids'] ##stacked automatically\n",
    "question_masks = sample['attention_mask'] ##stacked automatically\n",
    "\n",
    "#### reformulate questions\n",
    "t = time.time()\n",
    "max_response_length = 0\n",
    "total_length = config['txt_in_len']+config['txt_out_len']\n",
    "response_tensors = []\n",
    "game_data['question_reformulated'] = []\n",
    "for i in range(int(config['batch_size']/fbs)):\n",
    "    qt = question_tensors[i*fbs:(i+1)*fbs]\n",
    "    qm = question_masks[i*fbs:(i+1)*fbs]\n",
    "    response  = respond_to_batch(paraphrase_model, qt, txt_len=config['txt_out_len'], **{\"attention_mask\":qm})\n",
    "    response_tensors.append(response)\n",
    "    if response.shape[1] > max_response_length:\n",
    "        max_response_length = response.shape[1]\n",
    "\n",
    "pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "response_tensors = [pad_to_size(t,\n",
    "                                size=max_response_length,\n",
    "                                padding=pad_id) for t in response_tensors]\n",
    "\n",
    "response_tensors = torch.cat(response_tensors)\n",
    "for i in range(response_tensors.shape[0]):\n",
    "    game_data['question_reformulated'].append(tokenizer.decode(response_tensors[i].squeeze(), skip_special_tokens=True,clean_up_tokenization_spaces=True))\n",
    "\n",
    "timing['time/get_response'] = time.time()-t\n",
    "\n",
    "#### send reformulated questions to QA system\n",
    "t = time.time()\n",
    "qa_results = qa_pipeline(question=game_data[\"question_reformulated\"], context=sample[\"context\"])\n",
    "timing['time/build_input_sentiment'] = time.time()-t\n",
    "\n",
    "#### get f1 score for reformulated questions\n",
    "t = time.time()\n",
    "rewards = []\n",
    "for i in range(len(qa_results)):\n",
    "     score = f1_score(qa_results[i][\"answer\"], sample[\"answers\"][i])\n",
    "     rewards.append(torch.tensor(score, dtype=torch.float32, device=device).unsqueeze(-1))\n",
    "rewards = torch.cat(rewards)\n",
    "timing['time/get_sentiment_preds'] = time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run PPO training\n",
    "t = time.time()\n",
    "ppo_trainer = PPOTrainer(paraphrase_model, paraphrase_model_ref, **config)\n",
    "stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "timing['time/optimization'] = time.time()-t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
